{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Risk Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as mplt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve the Data\n",
    "\n",
    "The data is located in the Challenge Files Folder:\n",
    "\n",
    "* `lending_data.csv`\n",
    "\n",
    "Import the data using Pandas. Display the resulting dataframe to confirm the import was successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_size</th>\n",
       "      <th>interest_rate</th>\n",
       "      <th>borrower_income</th>\n",
       "      <th>debt_to_income</th>\n",
       "      <th>num_of_accounts</th>\n",
       "      <th>derogatory_marks</th>\n",
       "      <th>total_debt</th>\n",
       "      <th>loan_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10700.0</td>\n",
       "      <td>7.672</td>\n",
       "      <td>52800</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8400.0</td>\n",
       "      <td>6.692</td>\n",
       "      <td>43600</td>\n",
       "      <td>0.311927</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>13600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9000.0</td>\n",
       "      <td>6.963</td>\n",
       "      <td>46100</td>\n",
       "      <td>0.349241</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>16100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10700.0</td>\n",
       "      <td>7.664</td>\n",
       "      <td>52700</td>\n",
       "      <td>0.430740</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22700</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10800.0</td>\n",
       "      <td>7.698</td>\n",
       "      <td>53000</td>\n",
       "      <td>0.433962</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>23000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77531</th>\n",
       "      <td>19100.0</td>\n",
       "      <td>11.261</td>\n",
       "      <td>86600</td>\n",
       "      <td>0.653580</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>56600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77532</th>\n",
       "      <td>17700.0</td>\n",
       "      <td>10.662</td>\n",
       "      <td>80900</td>\n",
       "      <td>0.629172</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>50900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77533</th>\n",
       "      <td>17600.0</td>\n",
       "      <td>10.595</td>\n",
       "      <td>80300</td>\n",
       "      <td>0.626401</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>50300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77534</th>\n",
       "      <td>16300.0</td>\n",
       "      <td>10.068</td>\n",
       "      <td>75300</td>\n",
       "      <td>0.601594</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>45300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77535</th>\n",
       "      <td>15600.0</td>\n",
       "      <td>9.742</td>\n",
       "      <td>72300</td>\n",
       "      <td>0.585062</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>42300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77536 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       loan_size  interest_rate  borrower_income  debt_to_income  \\\n",
       "0        10700.0          7.672            52800        0.431818   \n",
       "1         8400.0          6.692            43600        0.311927   \n",
       "2         9000.0          6.963            46100        0.349241   \n",
       "3        10700.0          7.664            52700        0.430740   \n",
       "4        10800.0          7.698            53000        0.433962   \n",
       "...          ...            ...              ...             ...   \n",
       "77531    19100.0         11.261            86600        0.653580   \n",
       "77532    17700.0         10.662            80900        0.629172   \n",
       "77533    17600.0         10.595            80300        0.626401   \n",
       "77534    16300.0         10.068            75300        0.601594   \n",
       "77535    15600.0          9.742            72300        0.585062   \n",
       "\n",
       "       num_of_accounts  derogatory_marks  total_debt  loan_status  \n",
       "0                    5                 1       22800            0  \n",
       "1                    3                 0       13600            0  \n",
       "2                    3                 0       16100            0  \n",
       "3                    5                 1       22700            0  \n",
       "4                    5                 1       23000            0  \n",
       "...                ...               ...         ...          ...  \n",
       "77531               12                 2       56600            1  \n",
       "77532               11                 2       50900            1  \n",
       "77533               11                 2       50300            1  \n",
       "77534               10                 2       45300            1  \n",
       "77535                9                 2       42300            1  \n",
       "\n",
       "[77536 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the data\n",
    "lend_df = pd.read_csv(\"Resources/lending_data.csv\")\n",
    "lend_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Model Performance\n",
    "\n",
    "You will be creating and comparing two models on this data: a Logistic Regression, and a Random Forests Classifier. Before you create, fit, and score the models, make a prediction as to which model you think will perform better. You do not need to be correct! \n",
    "\n",
    "Write down your prediction in the designated cells in your Jupyter Notebook, and provide justification for your educated guess."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I believe linear regression makes more sense because the Random Forest model takes into account too much of the extraneous data that isn't related to credit scores. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Data into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_size</th>\n",
       "      <th>interest_rate</th>\n",
       "      <th>borrower_income</th>\n",
       "      <th>debt_to_income</th>\n",
       "      <th>num_of_accounts</th>\n",
       "      <th>derogatory_marks</th>\n",
       "      <th>total_debt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10700.0</td>\n",
       "      <td>7.672</td>\n",
       "      <td>52800</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8400.0</td>\n",
       "      <td>6.692</td>\n",
       "      <td>43600</td>\n",
       "      <td>0.311927</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>13600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9000.0</td>\n",
       "      <td>6.963</td>\n",
       "      <td>46100</td>\n",
       "      <td>0.349241</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>16100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10700.0</td>\n",
       "      <td>7.664</td>\n",
       "      <td>52700</td>\n",
       "      <td>0.430740</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10800.0</td>\n",
       "      <td>7.698</td>\n",
       "      <td>53000</td>\n",
       "      <td>0.433962</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>23000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_size  interest_rate  borrower_income  debt_to_income  num_of_accounts  \\\n",
       "0    10700.0          7.672            52800        0.431818                5   \n",
       "1     8400.0          6.692            43600        0.311927                3   \n",
       "2     9000.0          6.963            46100        0.349241                3   \n",
       "3    10700.0          7.664            52700        0.430740                5   \n",
       "4    10800.0          7.698            53000        0.433962                5   \n",
       "\n",
       "   derogatory_marks  total_debt  \n",
       "0                 1       22800  \n",
       "1                 0       13600  \n",
       "2                 0       16100  \n",
       "3                 1       22700  \n",
       "4                 1       23000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into X_train, X_test, y_train, y_test\n",
    "from sklearn.model_selection import train_test_split\n",
    "y = lend_df['loan_status'].values\n",
    "X = lend_df.drop('loan_status', axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling data based on the values\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create, Fit and Compare Models\n",
    "\n",
    "Create a Logistic Regression model, fit it to the data, and print the model's score. Do the same for a Random Forest Classifier. You may choose any starting hyperparameters you like. \n",
    "\n",
    "Which model performed better? How does that compare to your prediction? Write down your results and thoughts in the designated markdown cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=100000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a Logistic Regression model and print the model score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = LogisticRegression(max_iter=100000)\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=100000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Score: 0.9919177328380795\n",
      "Data Score: 0.9924680148576145\n"
     ]
    }
   ],
   "source": [
    "print(f\"Data Score: {classifier.score(X_train, y_train)}\")\n",
    "print(f\"Data Score: {classifier.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18699,    93],\n",
       "       [   53,   539]], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = y_test\n",
    "y_pred = classifier.predict(X_test)\n",
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9694593479158069\n"
     ]
    }
   ],
   "source": [
    "#accuracy check\n",
    "tp,tn,fp,fn = confusion_matrix(y_true, y_pred).ravel()\n",
    "acc = (tp  + tn) / (tp  + tn + fp + fn) \n",
    "print(f\"Accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     18792\n",
      "           1       0.85      0.91      0.88       592\n",
      "\n",
      "    accuracy                           0.99     19384\n",
      "   macro avg       0.93      0.95      0.94     19384\n",
      "weighted avg       0.99      0.99      0.99     19384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Random Forest Classifier model and print the model score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9975409272252029\n",
      "Test Score: 0.9917457697069748\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(random_state=1, n_estimators=500).fit(X_train_scaled, y_train)\n",
    "print(f'Training Score: {clf.score(X_train_scaled, y_train)}')\n",
    "print(f'Test Score: {clf.score(X_test_scaled, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.29066792e-01 2.74137485e-01 1.74521675e-01 1.58682971e-01\n",
      " 1.18902531e-01 8.06639163e-05 1.44607881e-01]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features = clf.feature_importances_\n",
    "print(features)\n",
    "mplt.bar(x = range(len(features)), height=features)\n",
    "mplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True,  True, False, False,  True])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "sel = SelectFromModel(clf)\n",
    "sel.fit(X_train_scaled, y_train)\n",
    "sel.get_support()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In my opinion the Linear Regression did perform better though the random forest classifier was very close. Accuracy 0.9924680148576145 vs 0.9917457697069748."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
